{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vivek-sagar/portfolio/blob/master/Transformers_movementData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGPkpFCl1PPY"
      },
      "source": [
        "## Transformers for Timeseries\n",
        "\n",
        "Click to run on colab (if you're not already there): [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/charlesollion/dlexperiments/blob/master/7-Transformers-Timeseries/Transformers_for_timeseries.ipynb) \n",
        "\n",
        "The goal of this notebook is to illustrate the use of a transformer for timeseries prediction.\n",
        "This notebook was built by Alice Martin and adapted to pytorch by Charles Ollion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "qrOtpRDjrSY2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMUQEguW7dj4"
      },
      "source": [
        "### Preparing the Dataset\n",
        "Energy consumption dataset from https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\n",
        "* gathers 10-min measurements of household appliances energy consumption (20 first features), coupled with local meteorological data (8 last features). \n",
        "* The time-series forecasting task is to predict the first 20 features, given as input data the 28 features. A window of observations of 12 time steps is considered to predict the next series of observations (this corresponds to a 2-hours window of observations. \n",
        "\n",
        "you may get the dataset (a single csv file) by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4X_aQcF7A8m",
        "outputId": "2800a1a0-5a47-49d2-885e-59d2fb27aef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/LuisM78/Appliances-energy-prediction-data/master/energydata_complete.csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# f = open(\"/content/drive/MyDrive/VaishData/TrainingData/subject_001_01__x.csv\", \"r\")\n",
        "\n",
        "train_x = pd.read_csv(\"/content/drive/MyDrive/VaishData/TrainingData/subject_001_01__x.csv\")\n",
        "train_y = pd.read_csv(\"/content/drive/MyDrive/VaishData/TrainingData/subject_001_01__y.csv\")\n",
        "\n",
        "print (train_x.shape)\n",
        "print (train_y.shape)\n",
        "train_x = train_x.astype(np.float32)\n",
        "train_y = train_y.astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqfYdtsF_B4O",
        "outputId": "b725eb1a-f257-4bcf-cfc1-58327093c44e"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37889, 6)\n",
            "(9472, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy each y value 4 times to match x size\n",
        "import itertools\n",
        "train_y_list=list(itertools.chain.from_iterable(itertools.repeat(x, 4) for x in train_y.values.tolist()))\n",
        "train_y = pd.DataFrame(train_y_list)\n",
        "print (train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2qOMq70_O1b",
        "outputId": "d2e401dc-cd0b-45b9-9f19-6c6d7017c291"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0\n",
            "0      0.0\n",
            "1      0.0\n",
            "2      0.0\n",
            "3      0.0\n",
            "4      0.0\n",
            "...    ...\n",
            "70163  0.0\n",
            "70164  0.0\n",
            "70165  0.0\n",
            "70166  0.0\n",
            "70167  0.0\n",
            "\n",
            "[70168 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = pd.concat([train_y, train_x], axis=1).values\n",
        "train_x = train_x[:-1]\n",
        "train_y = train_y[:-1]"
      ],
      "metadata": {
        "id": "ikPosDTOAF4l"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "p0bQB8uOv7xT"
      },
      "outputs": [],
      "source": [
        "def split_dataset_into_seq(dataset, start_index=0, end_index=None, history_size=13, step=1):\n",
        "    '''split the dataset to have sequence of observations of length history size'''\n",
        "    data = []\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset)\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i - history_size, i, step)\n",
        "        data.append(dataset[indices])\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "ajb5bl5bvtkh"
      },
      "outputs": [],
      "source": [
        "def split_dataset(data_x, data_y, TRAIN_SPLIT=0.7, VAL_SPLIT=0.5, save_path=None):\n",
        "    '''split the dataset into train, val and test splits'''\n",
        "    # normalization\n",
        "    data_mean = data_x.mean(axis=0)\n",
        "    data_std = data_x.std(axis=0)\n",
        "    data_x = (data_x - data_mean) / data_std\n",
        "    stats = (data_mean, data_std)\n",
        "    data = pd.concat([data_x, data_y], axis=1).values\n",
        "\n",
        "    data_in_seq = split_dataset_into_seq(data, start_index=0, end_index=None, history_size=13, step=1)\n",
        "\n",
        "    # split between validation dataset and test set:\n",
        "    train_data, val_data = train_test_split(data_in_seq, train_size=TRAIN_SPLIT, shuffle=True, random_state=123)\n",
        "    val_data, test_data = train_test_split(val_data, train_size=VAL_SPLIT, shuffle=True, random_state=123)\n",
        "\n",
        "    return train_data, val_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "34lFfEqjzdlB"
      },
      "outputs": [],
      "source": [
        "def split_fn(chunk):\n",
        "    \"\"\"to split the dataset sequences into input and targets sequences\"\"\"\n",
        "    inputs = torch.tensor(chunk[:, :-1, :-1], device=device)\n",
        "    targets = torch.tensor(chunk[:, -1, -1], device=device).type(torch.LongTensor)\n",
        "    # targets = torch.nn.functional.one_hot(targets.to(torch.int64), 4)\n",
        "    return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "n1ClBYcty4jL"
      },
      "outputs": [],
      "source": [
        "def data_to_dataset(train_data, val_data_x, test_data, batch_size=32):\n",
        "    '''\n",
        "    split each train split into inputs and targets \n",
        "    convert each train split into a tf.dataset\n",
        "    '''\n",
        "    x_train, y_train = split_fn(train_data)\n",
        "    x_val, y_val = split_fn(val_data)\n",
        "    x_test, y_test = split_fn(test_data)\n",
        "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
        "    test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Pm8flGcJ1PPi"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "VDzKvost8VUu"
      },
      "outputs": [],
      "source": [
        "train_data, val_data, test_data = split_dataset(train_x, train_y)\n",
        "train_data = train_data.astype(np.float32)\n",
        "val_data = val_data.astype(np.float32)\n",
        "test_data = test_data.astype(np.float32)\n",
        "train_dataset, val_dataset, test_dataset = data_to_dataset(train_data, val_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGacA_fS85sz"
      },
      "source": [
        "### Implementation of the Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "8KH-wFTB4e7I"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    '''Multi-head self-attention module'''\n",
        "    def __init__(self, D, H):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.H = H # number of heads\n",
        "        self.D = D # dimension\n",
        "        \n",
        "        self.wq = nn.Linear(D, D*H)\n",
        "        self.wk = nn.Linear(D, D*H)\n",
        "        self.wv = nn.Linear(D, D*H)\n",
        "\n",
        "        self.dense = nn.Linear(D*H, D)\n",
        "\n",
        "    def concat_heads(self, x):\n",
        "        '''(B, H, S, D) => (B, S, D*H)'''\n",
        "        B, H, S, D = x.shape\n",
        "        x = x.permute((0, 2, 1, 3)).contiguous()  # (B, S, H, D)\n",
        "        x = x.reshape((B, S, H*D))   # (B, S, D*H)\n",
        "        return x\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        '''(B, S, D*H) => (B, H, S, D)'''\n",
        "        B, S, D_H = x.shape\n",
        "        x = x.reshape(B, S, self.H, self.D)    # (B, S, H, D)\n",
        "        x = x.permute((0, 2, 1, 3))  # (B, H, S, D)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        q = self.wq(x)  # (B, S, D*H)\n",
        "        k = self.wk(x)  # (B, S, D*H)\n",
        "        v = self.wv(x)  # (B, S, D*H)\n",
        "\n",
        "        q = self.split_heads(q)  # (B, H, S, D)\n",
        "        k = self.split_heads(k)  # (B, H, S, D)\n",
        "        v = self.split_heads(v)  # (B, H, S, D)\n",
        "\n",
        "        attention_scores = torch.matmul(q, k.transpose(-1, -2)) #(B,H,S,S)\n",
        "        attention_scores = attention_scores / math.sqrt(self.D)\n",
        "\n",
        "        # add the mask to the scaled tensor.\n",
        "        if mask is not None:\n",
        "            attention_scores += (mask * -1e9)\n",
        "        \n",
        "        attention_weights = nn.Softmax(dim=-1)(attention_scores)\n",
        "        scaled_attention = torch.matmul(attention_weights, v)  # (B, H, S, D)\n",
        "        concat_attention = self.concat_heads(scaled_attention) # (B, S, D*H)\n",
        "        output = self.dense(concat_attention)  # (B, S, D)\n",
        "\n",
        "        return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "NNNfgv_g1PPj",
        "outputId": "5c96fa34-b3f3-495b-c941-ca16465ae9e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([9, 11, 8]), torch.Size([9, 5, 11, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "B, S, H, D = 9, 11, 5, 8\n",
        "mha = MultiHeadAttention(D, H)\n",
        "out, att = mha.forward(torch.zeros(B, S, D), mask=None)\n",
        "out.shape, att.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "bsiqoBF15qxb"
      },
      "outputs": [],
      "source": [
        "# Positional encodings\n",
        "def get_angles(pos, i, D):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(D))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(D, position=20, dim=3, device=device):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(D)[np.newaxis, :],\n",
        "                            D)\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    if dim == 3:\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    elif dim == 4:\n",
        "        pos_encoding = angle_rads[np.newaxis,np.newaxis,  ...]\n",
        "    return torch.tensor(pos_encoding, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "ZW26NwrB6LtR"
      },
      "outputs": [],
      "source": [
        "# function that implement the look_ahead mask for masking future time steps. \n",
        "def create_look_ahead_mask(size, device=device):\n",
        "    mask = torch.ones((size, size), device=device)\n",
        "    mask = torch.triu(mask, diagonal=1)\n",
        "    return mask  # (size, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "M885Un-C1PPk",
        "outputId": "6f683f87-a979-48df-f866-d4fb1530e27b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "create_look_ahead_mask(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "KUalYf-dtYwb"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, D, H, hidden_mlp_dim, dropout_rate):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.mlp_hidden = nn.Linear(D, hidden_mlp_dim)\n",
        "        self.mlp_out = nn.Linear(hidden_mlp_dim, D)\n",
        "        self.layernorm1 = nn.LayerNorm(D, eps=1e-9)\n",
        "        self.layernorm2 = nn.LayerNorm(D, eps=1e-9)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.mha = MultiHeadAttention(D, H)\n",
        "\n",
        "\n",
        "    def forward(self, x, look_ahead_mask):\n",
        "        \n",
        "        attn, attn_weights = self.mha(x, look_ahead_mask)  # (B, S, D)\n",
        "        attn = self.dropout1(attn) # (B,S,D)\n",
        "        attn = self.layernorm1(attn + x) # (B,S,D)\n",
        "\n",
        "        mlp_act = torch.relu(self.mlp_hidden(attn))\n",
        "        mlp_act = self.mlp_out(mlp_act)\n",
        "        mlp_act = self.dropout2(mlp_act)\n",
        "        \n",
        "        output = self.layernorm2(mlp_act + attn)  # (B, S, D)\n",
        "\n",
        "        return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "01B3u4ib1PPk",
        "outputId": "201beeb1-cf40-4e1d-c5fb-e63761dfb6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 7, 16]), torch.Size([5, 3, 7, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "dl = TransformerLayer(16, 3, 32, 0.1)\n",
        "out, attn = dl(x=torch.zeros(5, 7, 16), look_ahead_mask=None)\n",
        "out.shape, attn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "04VLiWfcuD4d"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    '''Transformer Decoder Implementating several Decoder Layers.\n",
        "    '''\n",
        "    def __init__(self, num_layers, D, H, hidden_mlp_dim, inp_features, out_features, dropout_rate):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.sqrt_D = torch.tensor(math.sqrt(D))\n",
        "        self.num_layers = num_layers\n",
        "        self.input_projection = nn.Linear(inp_features, D) # multivariate input\n",
        "        self.output_projection = nn.Linear(D, out_features) # multivariate output\n",
        "        self.pos_encoding = positional_encoding(D)\n",
        "        self.dec_layers = nn.ModuleList([TransformerLayer(D, H, hidden_mlp_dim, \n",
        "                                        dropout_rate=dropout_rate\n",
        "                                       ) for _ in range(num_layers)])\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        B, S, D = x.shape\n",
        "        attention_weights = {}\n",
        "        x = self.input_projection(x)\n",
        "        x *= self.sqrt_D\n",
        "        \n",
        "        x += self.pos_encoding[:, :S, :]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block = self.dec_layers[i](x=x,\n",
        "                                          look_ahead_mask=mask)\n",
        "            attention_weights['decoder_layer{}'.format(i + 1)] = block\n",
        "        \n",
        "        x = self.output_projection(x)\n",
        "        x = self.softmax(x)\n",
        "        x = x[:,S-1,:]\n",
        "        \n",
        "        \n",
        "        return x, attention_weights # (B,S,S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "qD8WG0B--V1x",
        "outputId": "c5849c0b-bce1-425a-ae69-1ce70dd3365e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 4]), torch.Size([32, 1, 12, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# Test Forward pass on the Transformer: \n",
        "transformer = Transformer(num_layers=1, D=32, H=1, hidden_mlp_dim=32,\n",
        "                                       inp_features=6, out_features=4, dropout_rate=0.1)\n",
        "transformer.to(device)\n",
        "(inputs, targets) = next(iter(train_dataset))\n",
        "                         \n",
        "S = inputs.shape[1]\n",
        "mask = create_look_ahead_mask(S)\n",
        "out, attn = transformer (x=inputs, mask=mask)\n",
        "out.shape, attn[\"decoder_layer1\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzrZUFZz6ia_"
      },
      "source": [
        "## Training the Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "eodznE9o1PPm",
        "outputId": "ef168a7c-7dff-4624-8f58-dc54b84e17e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of weight/biases matrices: 20 for a total of 6820 parameters \n"
          ]
        }
      ],
      "source": [
        "param_sizes = [p.numel() for p in transformer.parameters()]\n",
        "print(f\"number of weight/biases matrices: {len(param_sizes)} \"\n",
        "      f\"for a total of {np.sum(param_sizes)} parameters \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "JrU-R-LZ1PPm"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(num_layers=1, D=32, H=4, hidden_mlp_dim=32,\n",
        "                          inp_features=6, out_features=4, dropout_rate=0.1).to(device)\n",
        "optimizer = torch.optim.RMSprop(transformer.parameters(), \n",
        "                                lr=0.00005)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "g5r4xuru1PPn",
        "outputId": "484ad79e-0603-4e79-fcb1-85cc55117fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  0%|          | 0/20 [00:06<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-cd206b2023c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_look_ahead_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0msum_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target -9223372036854775808 is out of bounds."
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "n_epochs = 20\n",
        "niter = len(train_dataset)\n",
        "losses, val_losses = [], []\n",
        "\n",
        "for e in tqdm(range(n_epochs)):\n",
        "    \n",
        "    # one epoch on train set\n",
        "    transformer.train()\n",
        "    sum_train_loss = 0.0\n",
        "    for x,y in train_dataset:\n",
        "        S = x.shape[1]\n",
        "        mask = create_look_ahead_mask(S)\n",
        "        out, _ = transformer(x, mask)\n",
        "        loss = loss_fn(out, y)\n",
        "        sum_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    losses.append(sum_train_loss / niter)\n",
        "    \n",
        "    # Evaluate on val set\n",
        "    transformer.eval()\n",
        "    sum_val_loss = 0.0\n",
        "    for i, (x, y) in enumerate(val_dataset):\n",
        "        S = x.shape[1]\n",
        "        mask = create_look_ahead_mask(S)\n",
        "        out, _ = transformer(x, mask)\n",
        "        print (out[0])\n",
        "        print (y[0])\n",
        "        loss = loss_fn(out, y)\n",
        "        sum_val_loss += loss.item()\n",
        "    val_losses.append(sum_val_loss / (i + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N5CmFIi1PPn"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)\n",
        "plt.plot(val_losses);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALeWAQDFnAGx"
      },
      "source": [
        "### Evaluation on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRJJ-39R257V"
      },
      "outputs": [],
      "source": [
        "test_losses, test_preds  = [], []\n",
        "transformer.eval()\n",
        "for (x, y) in test_dataset:\n",
        "    S = x.shape[-2]\n",
        "    y_pred, _ = transformer(x,\n",
        "                            mask=create_look_ahead_mask(S))\n",
        "    loss_test = torch.nn.CrossEntropyLoss()(y_pred, y)  # (B,S)\n",
        "    test_losses.append(loss_test.item())\n",
        "    test_preds.append((y_pred.detach().cpu().numpy()))\n",
        "    print (np.argmax(y_pred.detach().cpu().numpy(), axis=1)[0])\n",
        "    print (y[0])\n",
        "    print (\"***\")\n",
        "test_preds = np.vstack(test_preds)\n",
        "print (test_preds)\n",
        "np.mean(test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1VCvxaklm0k"
      },
      "outputs": [],
      "source": [
        "# Display predictions vs ground truth: \n",
        "# we'll take one random element of the first batch\n",
        "# and display the first feature\n",
        "seq_len = 12\n",
        "index = np.random.randint(32)\n",
        "feature_num = 1\n",
        "\n",
        "x_test, _ = test_dataset.dataset.tensors\n",
        "x_test = x_test[index, :, feature_num].cpu().numpy()\n",
        "print (x_test)\n",
        "pred = test_preds[index, :, feature_num]\n",
        "x = np.linspace(1, seq_len, seq_len)\n",
        "print (pred)\n",
        "# plt.plot(x, pred, 'red', lw=2, label='predictions for sample: {}'.format(index))\n",
        "# plt.plot(x, x_test, 'cyan', lw=2, label='ground-truth for sample: {}'.format(index))\n",
        "# plt.legend(fontsize=10)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjTJlnjt1PPn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Transformers_movementData.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}